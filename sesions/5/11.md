## LangChain 블로그 시리즈 [11편]: LLM 애플리케이션 디버깅과 추적: LangSmith 시작하기

안녕하세요! LangChain 블로그 시리즈 독자 여러분. 어느덧 11편입니다. 우리는 지금까지 LangChain의 기본 구성 요소부터 시작하여 Chain, RAG, Memory, 그리고 스스로 생각하고 행동하는 Agent까지, 점점 더 복잡하고 강력한 LLM 애플리케이션을 만드는 여정을 함께 해왔습니다.

하지만 애플리케이션이 복잡해질수록, 특히 여러 컴포넌트가 상호작용하거나 Agent처럼 동적으로 작동하는 경우, 내부적으로 어떤 일이 벌어지고 있는지, 왜 예상과 다른 결과가 나왔는지 파악하기 어려워집니다. `verbose=True` 옵션으로 로그를 찍어보는 것도 도움이 되지만, 복잡한 흐름을 한눈에 파악하고 문제를 체계적으로 진단하기에는 한계가 있습니다.

바로 이때 필요한 것이 **LangSmith**입니다! LangSmith는 LangChain 애플리케이션의 개발, 디버깅, 추적, 평가 및 모니터링을 위해 특별히 설계된 플랫폼입니다. 마치 LLM 애플리케이션을 위한 현미경이자 블랙박스 분석 도구와 같습니다. 이번 시간에는 LangSmith를 설정하고 기본적인 사용법을 익혀, 우리의 LangChain 개발 경험을 한 단계 업그레이드해 보겠습니다.

---

**🎯 이번 시간에 배울 내용:**

1.  **LangSmith란 무엇인가? 왜 필요한가?**
2.  **LangSmith 시작하기: 설정 및 기본 연동** (API 키 발급, 환경 변수 설정)
3.  **LangSmith UI 둘러보기: 트레이스(Trace) 분석** (실행 흐름 시각화)
4.  **LangSmith를 활용한 디버깅 예시** (Agent, RAG 문제 진단)
5.  **피드백 및 모니터링 (간략 소개)**

---

### 1. LangSmith란 무엇인가? 왜 필요한가?

**LangSmith**는 LangChain 개발사인 LangChain Inc.에서 제공하는 **LLM 애플리케이션 개발 및 운영 플랫폼**입니다. 복잡하고 때로는 예측 불가능한 LLM 기반 애플리케이션의 내부 작동을 투명하게 들여다보고, 문제를 진단하며, 성능을 개선할 수 있도록 돕는 데 중점을 둡니다.

**왜 LangSmith가 필요할까요?**

* **복잡성(Complexity):** 현대 LLM 앱은 LLM 호출, 데이터 검색, 도구 사용, 여러 Chain 연결 등 다양한 컴포넌트로 구성됩니다. 이들 간의 상호작용을 추적하기 어렵습니다. 특히 Agent는 실행 경로가 동적이어서 더욱 복잡합니다.
* **비결정성(Non-Determinism):** 같은 입력에 대해서도 LLM은 약간씩 다른 결과를 내놓을 수 있어, 문제 재현 및 디버깅이 까다롭습니다.
* **가시성 부족(Lack of Visibility):** LLM API 호출 내부에서 정확히 어떤 프롬프트가 사용되었고, 어떤 응답이 생성되었는지, 각 단계에서 얼마나 시간이 걸리고 토큰은 얼마나 소모되었는지 파악하기 어렵습니다.
* **디버깅 어려움(Debugging Difficulty):** 오류가 발생했을 때, 전체 실행 흐름 중 어느 단계에서 어떤 입력값 때문에 문제가 생겼는지 특정하기 힘듭니다. Agent가 왜 특정 도구를 선택했는지 이유를 알기 어렵습니다.
* **평가 및 개선(Evaluation & Improvement):** 애플리케이션의 성능(품질, 속도, 비용)을 객관적으로 평가하고 개선 방향을 찾기 위한 데이터 수집 및 분석이 필요합니다. (이는 [14편]에서 더 자세히 다룹니다.)

LangSmith는 이러한 문제들을 해결하기 위해 **실행 과정의 모든 단계를 상세히 기록(Tracing)**하고, 이를 **시각적으로 탐색**할 수 있는 인터페이스를 제공하여 LLM 애플리케이션 개발의 필수적인 동반자 역할을 합니다.

### 2. LangSmith 시작하기: 설정 및 기본 연동

LangSmith를 사용하는 것은 놀랍도록 간단합니다. 몇 가지 환경 변수만 설정하면 기존 LangChain 코드를 거의 수정하지 않고도 모든 실행 내용을 LangSmith로 보낼 수 있습니다.

**단계:**

1.  **LangSmith 계정 생성 및 API 키 발급:**
    * LangSmith 웹사이트 ([https://smith.langchain.com/](https://smith.langchain.com/)) 에 접속하여 회원 가입을 합니다. (GitHub, Google 계정 등으로 간편 가입 가능)
    * 로그인 후, 왼쪽 메뉴의 `Settings` (또는 API Keys) 섹션으로 이동하여 API 키를 생성합니다. 생성된 키는 안전한 곳에 보관하세요.

2.  **환경 변수 설정:**
    * 여러분의 Python 환경(터미널, `.env` 파일, IDE 설정 등)에 다음 환경 변수들을 설정합니다.

    ```bash
    # LangSmith 추적 기능을 활성화합니다.
    export LANGCHAIN_TRACING_V2="true"

    # LangSmith 웹사이트에서 발급받은 API 키를 입력합니다.
    export LANGCHAIN_API_KEY="YOUR_LANGSMITH_API_KEY" # 실제 발급받은 키로 교체

    # (선택 사항이지만 강력히 권장) 실행 기록을 분류할 프로젝트 이름을 지정합니다.
    export LANGCHAIN_PROJECT="My LangChain Project" # 원하는 프로젝트 이름으로 변경 가능
    ```

    * **`LANGCHAIN_TRACING_V2="true"`:** 이 설정을 통해 LangChain의 모든 실행(`Runnable` 객체의 `invoke`, `batch`, `stream`, `ainvoke` 등 호출)이 LangSmith로 전송되도록 합니다.
    * **`LANGCHAIN_API_KEY`:** LangSmith 인증을 위한 키입니다.
    * **`LANGCHAIN_PROJECT`:** 설정하지 않으면 `default` 프로젝트로 기록됩니다. 여러 프로젝트를 관리하거나 팀과 협업할 때는 명시적으로 설정하는 것이 좋습니다.

**설정 확인:**
환경 변수를 설정한 후, 이전에 만들었던 간단한 LangChain 코드(예: `LLMChain` 실행)를 다시 실행해 보세요. 코드가 정상적으로 실행되었다면, 잠시 후 LangSmith 웹사이트의 해당 프로젝트 페이지에 실행 기록(Trace)이 나타나는 것을 확인할 수 있습니다.

### 3. LangSmith UI 둘러보기: 트레이스(Trace) 분석

환경 변수 설정 후 LangChain 코드를 실행하면, 모든 실행 정보가 **트레이스(Trace)** 형태로 LangSmith에 자동으로 기록됩니다. LangSmith UI에서 이 트레이스를 분석하는 방법을 알아봅시다.

1.  **프로젝트 및 실행 목록:**
    * LangSmith에 로그인하면 설정한 `LANGCHAIN_PROJECT` 이름으로 된 프로젝트를 볼 수 있습니다.
    * 프로젝트를 클릭하면 해당 프로젝트에서 실행된 모든 트레이스 목록이 최신순으로 나타납니다. 각 실행마다 이름(보통 사용된 최상위 `Runnable`의 이름), 시작 시간, 지연 시간(Latency), 총 토큰 사용량, 오류 여부 등이 표시됩니다.

2.  **트레이스 상세 보기 (Trace View):**
    * 목록에서 특정 실행 기록(트레이스)을 클릭하면 상세 보기 화면으로 이동합니다. 이곳이 LangSmith의 핵심입니다!
    * **개요(Overview):** 맨 위에는 전체 실행의 요약 정보(입력, 출력, 총 지연 시간, 총 토큰 등)가 표시됩니다.
    * **계층적 실행 흐름(Hierarchical View):** 아래에는 해당 실행을 구성하는 모든 단계가 **계층적 트리 구조**로 시각화되어 나타납니다.
        * 예: `AgentExecutor` 실행은 내부적으로 `LLMChain (Thought)`, `Tool (Action)`, `LLMChain (Final Answer)` 등의 하위 단계들로 구성될 수 있습니다. 각 단계는 들여쓰기로 구분되어 전체적인 호출 구조를 쉽게 파악할 수 있습니다.
    * **단계별 상세 정보(Step Details):** 트리에서 특정 단계를 클릭하면 화면 오른쪽에 해당 단계의 상세 정보가 나타납니다.
        * **Input:** 해당 단계에 입력된 값 (예: LLM 호출에 사용된 최종 프롬프트)
        * **Output:** 해당 단계에서 출력된 값 (예: LLM의 응답, Tool의 반환값)
        * **Metadata:** 실행 시간, 토큰 사용량, 사용된 모델 이름 등 유용한 메타데이터
        * **Error:** 해당 단계에서 오류가 발생했다면 오류 메시지와 스택 트레이스가 표시됩니다.

**핵심 가치:** 이 계층적 트레이스 뷰를 통해 복잡한 Chain이나 Agent가 내부적으로 어떤 과정을 거쳐 최종 결과에 도달했는지, 각 단계에서 어떤 데이터가 오고 갔는지, 어디서 시간이 많이 소요되었는지 등을 명확하게 파악할 수 있습니다.

### 4. LangSmith를 활용한 디버깅 예시

LangSmith가 실제 디버깅에 어떻게 도움이 되는지 몇 가지 시나리오를 통해 살펴보겠습니다.

**시나리오 1: Agent가 예상과 다른 도구를 사용할 때**

* **문제:** [9편]의 Agent에게 "파리의 현재 시간은?"이라고 물었는데, 검색 도구 대신 계산기 도구를 사용하려고 시도하며 오류가 발생했습니다.
* **LangSmith 활용:**
    1.  해당 실행의 트레이스를 엽니다.
    2.  `AgentExecutor` 트레이스 아래에서 Agent의 "생각(Thought)" 과정을 담은 `LLMChain` 또는 `ChatOpenAI` 단계를 찾습니다.
    3.  해당 단계의 **Output**을 확인합니다. LLM이 생성한 "Thought" 텍스트에 "Calculator"를 사용하겠다고 잘못 판단한 내용이 있을 것입니다. 또한 **Input**을 보면 어떤 프롬프트와 도구 설명 때문에 그런 판단을 내렸는지 추측할 수 있습니다.
    * **조치:** Agent가 도구를 더 잘 선택하도록 프롬프트를 수정하거나, 도구의 설명(docstring)을 더 명확하게 개선할 수 있습니다.

**시나리오 2: RAG 시스템이 관련 없는 문서를 검색할 때**

* **문제:** [7편]의 RAG 챗봇에게 특정 질문을 했는데, 질문과 관련 없는 내용의 문서를 기반으로 답변을 생성했습니다.
* **LangSmith 활용:**
    1.  RAG Chain 실행 트레이스를 엽니다.
    2.  실행 흐름에서 `Retriever` (예: `VectorStoreRetriever`) 단계를 찾습니다.
    3.  해당 단계의 **Input**을 확인하여 어떤 질문이 벡터 검색에 사용되었는지 확인합니다.
    4.  **Output**을 확인하여 실제로 어떤 문서(들)가 검색되었는지 (`Document` 객체 내용 확인) 살펴봅니다. 검색된 문서의 내용과 점수(score)를 보고 왜 관련 없는 문서가 뽑혔는지 분석합니다.
    * **조치:** 문서 분할(Splitting) 전략 변경, 임베딩 모델 개선, 검색 시 사용하는 유사도 점수 임계값 조정 등을 고려할 수 있습니다.

**시나리오 3: Chain 실행 중 오류 발생**

* **문제:** 복잡한 Chain 실행 중 알 수 없는 오류가 발생하며 멈췄습니다.
* **LangSmith 활용:**
    1.  오류가 발생한 트레이스를 엽니다. 오류가 발생한 트레이스는 목록에서 빨간색으로 표시됩니다.
    2.  트레이스 뷰에서 오류가 발생한 특정 단계(빨간색 느낌표 표시)를 찾습니다.
    3.  해당 단계의 상세 정보에서 **Error** 탭을 확인하여 오류 메시지와 스택 트레이스를 통해 원인을 파악합니다. 또한 **Input** 탭을 통해 어떤 입력값이 오류를 유발했는지 확인할 수 있습니다.
    * **조치:** 해당 컴포넌트의 코드나 입력값을 수정합니다.

### 5. 피드백 및 모니터링 (간략 소개)

LangSmith는 단순한 디버깅 도구를 넘어, 애플리케이션의 품질을 관리하고 개선하는 데도 도움을 줍니다.

* **피드백(Feedback):** 트레이스 상세 보기 화면에서 각 실행 결과에 대해 "좋아요(👍)" 또는 "싫어요(👎)"와 같은 피드백을 남길 수 있습니다. 이 피드백 데이터는 나중에 모델 성능 평가나 개선 데이터셋 구축에 활용될 수 있습니다. ([14편] 평가(Evaluation)에서 자세히 다룸)
* **모니터링(Monitoring):** LangSmith는 프로젝트별로 실행 시간, 비용(토큰 사용량), 오류율, 사용자 피드백 점수 등의 통계를 대시보드 형태로 제공합니다. 이를 통해 애플리케이션의 전반적인 상태와 성능 추이를 모니터링할 수 있습니다.

---

### 6. 마무리

이번 시간에는 LangChain 애플리케이션 개발의 필수 동반자인 **LangSmith**를 소개하고, 기본적인 설정 방법과 트레이스 분석을 통한 디버깅 활용법을 알아보았습니다. LangSmith를 사용하면 복잡한 LLM 애플리케이션의 내부를 투명하게 들여다보고, 문제의 원인을 신속하게 파악하며, 성능을 체계적으로 관리할 수 있습니다.

아직 LangSmith를 사용해보지 않으셨다면, 지금 바로 계정을 만들고 여러분의 LangChain 프로젝트에 적용해 보세요. 개발 생산성이 크게 향상되는 것을 경험하실 수 있을 것입니다!

다음 **[12편]**에서는 드디어 우리가 만든 LangChain 애플리케이션(Chain, Agent 등)을 다른 사람들이 쉽게 사용할 수 있도록 **API 형태로 배포**하는 방법, **LangServe**에 대해 알아보겠습니다.

LangSmith 사용에 대해 궁금한 점이 있다면 언제든지 댓글로 질문해주세요!

---

**다음 편 예고:** [12편] 내 LangChain 앱을 API로! LangServe를 이용한 간편 배포

**참고 자료:**

* LangSmith 공식 문서: [https://docs.smith.langchain.com/](https://docs.smith.langchain.com/)