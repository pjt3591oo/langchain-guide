## LangChain 블로그 시리즈 [10편]: LangChain Agent 심화: 커스텀 Tool 제작 및 Agent 종류

안녕하세요\! LangChain 블로그 시리즈의 독자 여러분. 지난 [9편]에서는 LangChain Agent의 기본 개념과 ReAct 프레임워크, 그리고 검색이나 계산기 같은 기본적인 도구(Tool)를 활용하는 방법을 배웠습니다. Agent가 스스로 추론하고 도구를 사용하는 모습이 인상적이었을 것입니다.

이번 10편에서는 Agent의 능력을 한층 더 끌어올리는 방법을 알아봅니다. 바로 **우리만의 특정 요구사항에 맞는 도구를 직접 제작**하고, 다양한 상황에 최적화된 **여러 종류의 Agent**들을 살펴보는 것입니다. 이를 통해 Agent를 더욱 강력하고 유연하게 활용할 수 있게 될 것입니다.

-----

**🎯 이번 시간에 배울 내용:**

1.  **왜 커스텀 도구(Custom Tool)가 필요한가?**
2.  **나만의 도구 만들기:** `@tool` 데코레이터 활용법 (핵심\!)
3.  **다양한 Agent 종류 탐구:**
      * 대화형 Agent (Conversational Agent)
      * OpenAI Functions Agent
4.  **어떤 Agent를 선택해야 할까?**
5.  **Agent 디버깅 팁 (간략히)**

-----

### 1\. 왜 커스텀 도구(Custom Tool)가 필요한가?

LangChain이 제공하는 기본 도구(검색, 계산기, Python REPL 등)는 매우 유용하지만, 실제 애플리케이션 개발 시에는 이것만으로는 부족할 때가 많습니다. 예를 들어 다음과 같은 상황을 생각해 볼 수 있습니다.

  * 우리 회사 **내부 데이터베이스**에서 고객 정보를 조회해야 할 때
  * 특정 **사내 API**를 호출하여 재고 현황을 확인해야 할 때
  * **특정 형식**으로 데이터를 가공하거나 **독자적인 로직**을 수행해야 할 때
  * 회사의 **자주 묻는 질문(FAQ) 문서**에서 답변을 찾아야 할 때 (RAG 기반 도구)

이처럼 Agent가 우리의 **고유한 시스템이나 데이터, 로직과 상호작용**해야 할 때, 바로 \*\*커스텀 도구(Custom Tool)\*\*가 필요합니다. 커스텀 도구를 통해 Agent의 활용 범위를 무한히 확장할 수 있습니다.

### 2\. 나만의 도구 만들기: `@tool` 데코레이터 활용법

LangChain은 커스텀 도구를 매우 쉽게 만들 수 있는 방법을 제공합니다. 가장 간편하고 추천하는 방식은 `@tool` 데코레이터를 사용하는 것입니다.

**핵심:** 일반적인 Python 함수를 만들고, 그 함수 위에 `@tool` 데코레이터만 붙여주면 됩니다\! 이때 함수의 \*\*독스트링(docstring)\*\*이 매우 중요합니다. Agent(LLM)는 이 독스트링을 읽고 \*\*"이 도구가 어떤 기능을 하는지, 언제 사용해야 하는지"\*\*를 판단하기 때문입니다.

**예제: 현재 날짜와 시간을 알려주는 커스텀 도구**

```python
import os
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool, tool # tool 데코레이터 임포트
from langchain import hub

# --- 1. 환경 변수 설정 (필요시) ---
# os.environ["OPENAI_API_KEY"] = "YOUR_API_KEY"

# --- 2. LLM 준비 ---
llm = ChatOpenAI(temperature=0, model_name='gpt-4')

# --- 3. 커스텀 도구 정의 ---
@tool
def get_current_datetime(query: str) -> str:
  """
  현재 날짜와 시간을 알아야 할 때 사용합니다.
  입력(query)은 사용하지 않지만, 형식상 필요합니다.
  현재 날짜와 시간을 문자열 형태로 반환합니다.
  예: '현재 시간은 2025년 5월 4일 오후 5시 55분입니다.'
  """
  now = datetime.now()
  # 사용자가 이해하기 쉬운 형태로 포맷팅 (한국 시간 기준 예시)
  return f"현재 시간은 {now.strftime('%Y년 %m월 %d일 %p %I시 %M분')}입니다."

# (선택) 예제: 간단한 사용자 프로필 조회 도구 (사내 시스템 연동 가정)
user_database = {
    "Alice": {"email": "alice@example.com", "department": "Engineering"},
    "Bob": {"email": "bob@sample.org", "department": "Marketing"}
}

@tool
def get_user_profile(username: str) -> str:
  """
  회사 직원의 이메일 주소나 부서 등 프로필 정보가 필요할 때 사용합니다.
  사용자 이름(username)을 입력받아 해당 사용자의 프로필 정보를 반환합니다.
  만약 사용자를 찾을 수 없으면, '사용자를 찾을 수 없습니다.' 라고 답합니다.
  """
  if username in user_database:
    profile = user_database[username]
    return f"{username}의 정보: 이메일={profile.get('email', 'N/A')}, 부서={profile.get('department', 'N/A')}"
  else:
    return f"사용자 '{username}'을(를) 찾을 수 없습니다."

# --- 4. 사용할 도구 리스트 정의 (커스텀 도구 포함) ---
tools = [get_current_datetime, get_user_profile] # @tool로 만든 함수는 바로 리스트에 추가 가능

# --- 5. Agent가 사용할 프롬프트 가져오기 ---
prompt = hub.pull("hwchase17/react")

# --- 6. Agent 생성 ---
agent = create_react_agent(llm, tools, prompt)

# --- 7. Agent Executor 생성 ---
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# --- 8. Agent 실행 (커스텀 도구 사용 유도) ---
print("\n--- Agent 실행 예제 1: 현재 시간 묻기 ---")
query1 = "지금 몇 시야?"
response1 = agent_executor.invoke({"input": query1})
print(f"질문: {query1}")
print(f"답변: {response1['output']}")

print("\n--- Agent 실행 예제 2: 직원 정보 묻기 ---")
query2 = "Alice의 이메일 주소 알려줘."
response2 = agent_executor.invoke({"input": query2})
print(f"질문: {query2}")
print(f"답변: {response2['output']}")

print("\n--- Agent 실행 예제 3: 없는 직원 정보 묻기 ---")
query3 = "Charlie의 부서는 어디야?"
response3 = agent_executor.invoke({"input": query3})
print(f"질문: {query3}")
print(f"답변: {response3['output']}")
```

**코드 설명:**

1.  `@tool` 데코레이터를 `langchain.tools`에서 임포트합니다.
2.  일반 Python 함수 (`get_current_datetime`, `get_user_profile`)를 정의합니다.
3.  **매우 중요:** 함수 정의 바로 아래에 명확하고 상세한 독스트링(docstring)을 작성합니다. 이 독스트링은 Agent가 도구를 이해하고 언제 사용할지 결정하는 데 사용됩니다. 함수가 어떤 인자를 받는지, 무엇을 반환하는지, 어떤 상황에 유용한지를 설명해야 합니다. 타입 힌트(`query: str`, `username: str -> str`)도 Agent가 인자를 올바르게 전달하는 데 도움을 줄 수 있습니다.
4.  `@tool` 데코레이터를 함수 위에 붙여줍니다.
5.  이렇게 `@tool`로 정의된 함수는 별도의 `Tool` 클래스 래핑 없이 바로 `tools` 리스트에 추가할 수 있습니다.
6.  나머지 과정(Agent 생성, Executor 생성 및 실행)은 [9편]과 동일합니다.

Agent를 실행하면, `verbose=True` 옵션을 통해 Agent가 질문을 이해하고 적절한 커스텀 도구(`get_current_datetime` 또는 `get_user_profile`)를 선택하여 실행하는 과정을 확인할 수 있습니다. 독스트링이 얼마나 중요한지 다시 한번 강조합니다\!

**(참고: `BaseTool` 상속)**
더 복잡한 로직, 비동기 실행, 또는 인자 스키마를 정교하게 정의하고 싶을 때는 `BaseTool` 클래스를 상속하여 커스텀 도구를 만들 수도 있습니다. 하지만 대부분의 경우 `@tool` 데코레이터로 충분합니다.

### 3\. 다양한 Agent 종류 탐구

[9편]에서 사용한 ReAct Agent는 범용적으로 훌륭하지만, LangChain은 특정 작업에 더 최적화된 다른 종류의 Agent들도 제공합니다.

**a) 대화형 Agent (Conversational Agent)**

  * **목적:** 사용자와 여러 턴에 걸쳐 자연스럽게 대화하며 맥락을 유지해야 하는 챗봇 시나리오에 적합합니다.
  * **특징:**
      * [8편]에서 배운 **Memory**와 통합되어 이전 대화 내용을 기억하고 활용합니다.
      * 프롬프트 자체가 대화 기록을 고려하도록 설계되어 있습니다. (예: `chat_history` 변수 포함)
  * **사용법:** `create_react_agent`를 사용할 때 대화형 프롬프트 (`hub.pull("hwchase17/react-chat")` 등)를 사용하고, `AgentExecutor`를 생성할 때 `memory` 객체를 함께 전달해주면 됩니다.

<!-- end list -->

```python
# Conversational Agent 예시 (개념적 코드)
from langchain.memory import ConversationBufferMemory
# ... (llm, tools 정의는 동일하다고 가정)

# 대화형 프롬프트 가져오기
conversational_prompt = hub.pull("hwchase17/react-chat")

# 대화 기록을 위한 메모리 설정
memory = ConversationBufferMemory(memory_key="chat_history") # 프롬프트의 변수명과 일치

# 대화형 Agent 생성
conversational_agent = create_react_agent(llm, tools, conversational_prompt)

# Agent Executor에 memory 추가
conversational_executor = AgentExecutor(
    agent=conversational_agent,
    tools=tools,
    memory=memory, # 메모리 전달
    verbose=True
)

# 실행 (여러 턴 대화 가능)
response = conversational_executor.invoke({"input": "안녕하세요!"})
print(response['output'])

response = conversational_executor.invoke({"input": "제 이름은 무엇일까요?"}) # 이전 대화 내용 기억하는지 확인
print(response['output'])
```

**b) OpenAI Functions Agent**

  * **목적:** OpenAI의 "Function Calling" 기능을 활용하여 더 안정적이고 효율적으로 도구를 사용하고자 할 때 적합합니다. (OpenAI 모델 사용 시 강력 추천)
  * **특징:**
      * LLM이 직접 어떤 함수(도구)를 호출할지, 그리고 그 함수에 어떤 인자를 **JSON 형식**으로 전달할지 결정합니다. ReAct의 텍스트 기반 추론보다 더 구조적이고 오류가 적습니다.
      * 도구의 이름, 설명뿐만 아니라 \*\*인자의 스키마(타입, 필수 여부 등)\*\*까지 LLM에게 명확하게 전달됩니다. (`@tool` 데코레이터 사용 시 LangChain이 자동으로 처리해 줍니다.)
      * 때로는 ReAct 방식보다 빠르고 비용 효율적일 수 있습니다.
  * **사용법:** `create_openai_functions_agent` 함수를 사용하여 Agent를 생성합니다. `@tool`로 정의된 도구들은 대부분 그대로 호환됩니다.

<!-- end list -->

```python
# OpenAI Functions Agent 예시
from langchain.agents import create_openai_functions_agent
# ... (llm, tools - @tool로 정의된 것들 - 은 동일하다고 가정)

# OpenAI Functions Agent용 프롬프트 가져오기
openai_funcs_prompt = hub.pull("hwchase17/openai-functions-agent")

# OpenAI Functions Agent 생성
openai_funcs_agent = create_openai_functions_agent(llm, tools, openai_funcs_prompt)

# Agent Executor 생성
openai_funcs_executor = AgentExecutor(
    agent=openai_funcs_agent,
    tools=tools,
    verbose=True
)

# 실행
query = "현재 시간 알려주고, Alice의 부서도 알려줘."
response = openai_funcs_executor.invoke({"input": query})
print(response['output'])
```

OpenAI Functions Agent는 특히 여러 도구를 조합하거나, 도구에 전달할 인자를 정확하게 추출해야 하는 경우 매우 강력합니다.

**(기타 Agent)**
LangChain에는 Self-Ask with Search Agent (검색을 통해 답변의 근거를 찾는 데 특화), Plan-and-Execute Agent (복잡한 작업을 계획하고 단계별로 실행) 등 더 많은 종류의 Agent가 있습니다. 필요에 따라 공식 문서를 참고하여 탐색해 볼 수 있습니다.

### 4\. 어떤 Agent를 선택해야 할까?

  * **범용적인 작업, ReAct 방식의 추론 과정 확인:** `create_react_agent` (기본 ReAct)
  * **챗봇처럼 대화 맥락 유지가 중요할 때:** `create_react_agent` + 대화형 프롬프트 + Memory (Conversational ReAct)
  * **OpenAI 모델 사용 & 안정적인 도구 호출 및 인자 전달:** `create_openai_functions_agent` (OpenAI Functions)

상황과 요구사항, 사용하는 LLM 모델에 맞춰 적절한 Agent를 선택하는 것이 중요합니다. OpenAI Functions Agent가 가능하다면 우선적으로 고려해볼 만합니다.

### 5\. Agent 디버깅 팁 (간략히)

Agent는 내부적으로 복잡한 추론 과정을 거치기 때문에 예상대로 동작하지 않을 때 디버깅이 까다로울 수 있습니다.

  * **`verbose=True` 활용:** `AgentExecutor` 생성 시 이 옵션을 켜면 Agent의 Thought, Action, Observation 과정을 상세히 볼 수 있어 문제 파악에 큰 도움이 됩니다.
  * **도구 설명(Docstring) 확인:** Agent가 도구를 잘못 선택하거나 사용하지 않는다면, 도구의 설명이 명확하지 않거나 LLM이 오해할 소지가 있는지 확인하고 수정해야 합니다.
  * **프롬프트 검토:** Agent의 행동은 프롬프트에 크게 영향을 받습니다. 사용 중인 프롬프트 템플릿을 이해하고, 필요하다면 수정(커스터마이징)하는 것도 방법입니다.
  * **LangSmith (다음 편 예고\!):** Agent의 복잡한 실행 과정을 시각적으로 추적하고 분석하는 데는 LangSmith와 같은 도구가 매우 유용합니다. [11편]에서 자세히 다룰 예정입니다\!

-----

### 6\. 마무리

이번 시간에는 LangChain Agent를 더욱 강력하게 만드는 두 가지 핵심 요소, \*\*커스텀 도구 제작(`@tool`)\*\*과 \*\*다양한 Agent 종류(Conversational, OpenAI Functions)\*\*에 대해 알아보았습니다. 이제 여러분은 Agent에게 여러분만의 특별한 능력을 부여하고, 특정 작업에 더 최적화된 방식으로 Agent를 활용할 수 있게 되었습니다.

커스텀 도구를 직접 만들어보고, 여러 종류의 Agent를 실험해보면서 그 차이점과 가능성을 직접 느껴보시길 바랍니다. 다음 \*\*[11편]\*\*에서는 이렇게 만든 LLM 애플리케이션(Chain, Agent 등)의 실행 과정을 추적하고 디버깅하는 데 필수적인 도구, **LangSmith**에 대해 자세히 알아보겠습니다.

궁금한 점이나 공유하고 싶은 아이디어가 있다면 언제든지 댓글로 남겨주세요\!

-----

**다음 편 예고:** [11편] LLM 애플리케이션 디버깅과 추적: LangSmith 시작하기

**참고 자료:**

  * LangChain Custom Tools: [https://www.google.com/search?q=https://python.langchain.com/docs/modules/tools/custom\_tools/](https://www.google.com/search?q=https://python.langchain.com/docs/modules/tools/custom_tools/)
  * LangChain Agent Types: [https://www.google.com/search?q=https://python.langchain.com/docs/modules/agents/agent\_types/](https://www.google.com/search?q=https://python.langchain.com/docs/modules/agents/agent_types/)
  * OpenAI Function Calling: [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling)