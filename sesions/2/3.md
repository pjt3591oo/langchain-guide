네, LangChain 블로그 시리즈의 세 번째 포스팅을 작성해 드리겠습니다.

---

## [LangChain 블로그 3편] LangChain의 심장, Chain: 단순 호출을 넘어 워크플로우 구축하기 (LCEL 소개)

안녕하세요! LangChain 블로그 시리즈 3편입니다. 지난 [1편]과 [2편]에서는 LangChain의 기본 개념과 핵심 구성 요소인 **Models, Prompts, Output Parsers**에 대해 알아보았습니다. 이들은 LLM 애플리케이션을 만드는 데 필요한 강력한 재료들이었죠.

이번 편에서는 이 재료들을 **조합하여 실제 작동하는 워크플로우를 만드는 방법**, 즉 LangChain의 **Chain**에 대해 알아봅니다. 특히, LangChain의 현대적이고 강력한 조합 방식인 **LCEL(LangChain Expression Language)** 을 중심으로 설명하며, 왜 LCEL이 LangChain 개발의 핵심으로 자리 잡았는지 이해하게 되실 겁니다.

**1. Chain이란 무엇인가? 왜 필요할까?**

LLM 애플리케이션은 단순히 LLM을 한 번 호출하는 것으로 끝나지 않는 경우가 많습니다.

* 사용자 입력을 받아 -> 프롬프트를 만들고 -> LLM을 호출하고 -> 그 결과를 파싱하거나
* LLM 호출 결과를 -> 다른 LLM의 입력으로 사용하거나
* 외부 데이터베이스에서 정보를 가져와 -> 프롬프트에 포함시켜 -> LLM에게 질문하는 등

이처럼 **여러 단계의 작업들을 순차적 또는 병렬적으로 연결하여 하나의 목표를 달성하는 흐름**을 만들어야 합니다. LangChain에서는 이러한 **컴포넌트들의 조합 또는 실행 흐름**을 **Chain**이라고 부릅니다.

**2. 과거의 방식 (참고): `LLMChain`**

과거 LangChain 버전에서는 `LLMChain`과 같은 클래스를 사용하여 기본적인 Chain을 만들었습니다. `LLMChain`은 주로 **PromptTemplate + LLM (+ OutputParser)** 의 조합을 캡슐화하는 역할을 했습니다.

```python
# 이전 방식 예시 (개념 이해용, 현재는 LCEL 권장)
# 필요한 라이브러리 설치 (이전 포스팅에서 설치했다면 생략)
# pip install langchain langchain-openai python-dotenv pydantic

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain # 이전 방식의 Chain
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

# 환경 변수 로드 및 모델 초기화 (2편 내용)
load_dotenv()
chat_model = ChatOpenAI(temperature=0.7, model_name="gpt-3.5-turbo")

# Pydantic 모델 및 Parser 정의 (2편 내용)
class Joke(BaseModel):
    setup: str = Field(description="question to set up a joke")
    punchline: str = Field(description="answer to resolve the joke")
pydantic_parser = PydanticOutputParser(pydantic_object=Joke)
format_instructions = pydantic_parser.get_format_instructions()

# 프롬프트 템플릿 정의 (2편 내용)
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI that tells jokes based on a topic."),
    ("human", "Tell me a joke about {topic}.\n{format_instructions}")
])

# LLMChain 생성 (Prompt + LLM)
# 참고: LLMChain 자체에는 output_parser를 직접 통합하는 것이 조금 번거로웠습니다.
chain_old = LLMChain(llm=chat_model, prompt=prompt)

# Chain 실행
topic = "bears"
# formatted_prompt = prompt.format_prompt(topic=topic, format_instructions=format_instructions).to_messages() # 직접 포맷팅 필요
# response_old = chain_old.invoke({"topic": topic, "format_instructions": format_instructions}) # 입력 변수 전달

# print(response_old) # {'topic': 'bears', 'format_instructions': '...', 'text': '{\n\t"setup": "Why don\'t bears wear shoes?",\n\t"punchline": "Because they have bear feet!"\n}'}

# 결과 파싱은 별도로 필요
# try:
#     parsed_joke = pydantic_parser.parse(response_old['text'])
#     print(parsed_joke)
# except Exception as e:
#     print("Parsing error:", e)

```

`LLMChain`은 간단한 조합에는 유용했지만, 더 복잡한 Chain을 만들거나 스트리밍, 비동기 처리 등을 구현하기에는 다소 번거로운 면이 있었습니다.

**3. 현대적인 방식: LCEL (LangChain Expression Language)**

이러한 점들을 개선하고 더 직관적이며 강력한 Chain 구성을 위해 등장한 것이 바로 **LCEL (LangChain Expression Language)** 입니다. LCEL은 LangChain의 **모든 컴포넌트(Model, Prompt, Parser, Retriever 등)를 `Runnable`이라는 표준 인터페이스로 취급**하고, 이 `Runnable`들을 **파이프(`|`) 연산자**를 사용하여 마치 리눅스 셸 파이프라인처럼 자연스럽게 연결할 수 있게 해줍니다.

```python
# LCEL 방식으로 재구성

# 1. 각 컴포넌트 준비 (Model, Prompt, Parser - 이미 위에서 준비됨)

# 2. LCEL을 사용하여 Chain 연결 (파이프 '|' 사용)
# PromptTemplate -> ChatModel -> OutputParser 순서로 연결
chain_lcel = prompt | chat_model | pydantic_parser

# 3. Chain 실행 (훨씬 간결!)
topic = "cats"
result = chain_lcel.invoke({"topic": topic, "format_instructions": format_instructions})

print(type(result)) # <class '__main__.Joke'> - 바로 Pydantic 객체로 파싱됨!
print(result)       # setup='Why was the cat sitting on the computer?' punchline='To keep an eye on the mouse!'
print("농담:", result.setup)
print("답변:", result.punchline)
```

LCEL 방식이 훨씬 간결하고 가독성이 좋은 것을 볼 수 있습니다. `invoke`를 호출하면 입력(`topic`, `format_instructions`)이 `prompt`로 전달되어 메시지가 생성되고, 이 메시지가 `chat_model`로 전달되어 LLM 응답(JSON 문자열)이 생성되며, 마지막으로 이 응답이 `pydantic_parser`로 전달되어 최종적으로 `Joke` 객체로 파싱됩니다.

**LCEL의 장점:**

* **선언적 구성 (Declarative Composition):** 코드가 Chain의 '실행 방법'보다는 '구성 요소'에 집중하여 가독성이 높고 유지보수가 용이합니다.
* **스트리밍 지원 (Streaming Support):** `chain.stream()` 메서드를 사용하여 LLM의 응답을 실시간으로(토큰 단위로) 받을 수 있습니다. 챗봇 UI 등에서 유용합니다.
* **비동기 지원 (Async Support):** `chain.ainvoke()`, `chain.astream()` 등 비동기 메서드를 기본적으로 지원하여 효율적인 I/O 처리가 가능합니다.
* **병렬 처리 (Parallel Execution):** 여러 `Runnable`을 동시에 실행하고 결과를 조합하는 것이 용이합니다. (다음 편에서 자세히!)
* **자동 추적 (LangSmith Integration):** LCEL로 구성된 Chain은 LangSmith와 같은 추적 도구에서 각 단계의 입력과 출력을 시각적으로 확인하기 용이합니다.

**LCEL 스트리밍 예시:**

```python
# 스트리밍 예시
# 스트리밍 시에는 최종 파서가 문자열을 기대하는 경우가 많으므로, StrOutputParser를 사용하거나 파싱 단계를 제외합니다.
from langchain_core.output_parsers import StrOutputParser

# Parser를 StrOutputParser로 변경하여 스트리밍 확인
stream_chain = prompt | chat_model | StrOutputParser()

print("\n--- Streaming Start ---")
# stream 메서드 사용
for chunk in stream_chain.stream({"topic": "dogs", "format_instructions": format_instructions}):
    print(chunk, end="", flush=True) # 청크(토큰)가 생성될 때마다 바로 출력
print("\n--- Streaming End ---")
```

위 코드를 실행하면, 농담이 한 번에 완성되어 출력되는 것이 아니라, LLM이 생성하는 대로 단어 또는 구문 단위로 실시간 출력되는 것을 볼 수 있습니다.

**Runnable 프로토콜이란?**

LCEL의 핵심은 `Runnable` 프로토콜입니다. LangChain의 주요 컴포넌트들(PromptTemplate, ChatModel, OutputParser, Retriever 등)은 모두 이 `Runnable` 인터페이스를 구현하고 있습니다. `Runnable`은 다음과 같은 표준 메서드를 제공합니다.

* `invoke`: 단일 입력으로 Chain을 실행하고 최종 결과 반환
* `batch`: 여러 입력에 대해 Chain을 병렬로 실행하고 결과 리스트 반환
* `stream`: 단일 입력으로 Chain을 실행하고 결과 청크(부분)를 스트리밍 (실시간 반환)
* `ainvoke`, `abatch`, `astream`: 위 메서드들의 비동기 버전

LCEL은 이 `Runnable`들을 `|` 연산자로 연결하여 새로운 `RunnableSequence`를 만듭니다. 즉, **LCEL Chain 자체가 또 다른 `Runnable`** 이기 때문에, 복잡한 Chain도 단계적으로 쉽게 구성하고 재사용할 수 있습니다.

**마무리하며**

이번 편에서는 LangChain의 핵심인 **Chain**의 개념과, 컴포넌트들을 유연하고 강력하게 조합하는 **LCEL(LangChain Expression Language)** 에 대해 알아보았습니다. LCEL은 `Runnable` 인터페이스와 파이프(`|`) 연산자를 통해 Chain 구성을 혁신적으로 개선했으며, 스트리밍, 비동기 처리 등 현대적인 애플리케이션 개발에 필수적인 기능들을 쉽게 구현할 수 있도록 지원합니다.

이제 여러분은 LangChain의 기본 재료(Models, Prompts, Parsers)를 조합하여 간단한 워크플로우(Chain)를 만들 준비가 되었습니다!

**다음 편 예고:**

다음 [4편]에서는 **LCEL을 더욱 깊이 있게** 다룹니다. `Runnable` 인터페이스의 다양한 메서드(`batch`, `stream` 등) 활용법과, `RunnablePassthrough`, `RunnableParallel` 등을 사용하여 **더 복잡하고 유연한 데이터 흐름을 제어하는 방법**에 대해 알아보겠습니다.

LCEL을 직접 사용해보시고 궁금한 점은 댓글로 남겨주세요!

---

세 번째 포스팅이 완료되었습니다. 이어서 **[4편] LCEL 심화: Runnable 인터페이스와 다양한 Chain 조합** 포스팅을 작성해 드릴까요?